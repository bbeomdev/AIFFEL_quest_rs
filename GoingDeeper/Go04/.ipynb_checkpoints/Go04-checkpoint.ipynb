{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1455cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import tensorflow\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from konlpy.tag import Mecab\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb49bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"korean-english-park.train.ko\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ko_lines = f.readlines()\n",
    "    \n",
    "with open(\"korean-english-park.train.en\", \"r\", encoding=\"utf-8\") as f:\n",
    "    en_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acc78ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94123"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'ko':ko_lines, 'en':en_lines})\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f907fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 중복제거 len 77591\n"
     ]
    }
   ],
   "source": [
    "data = data.drop_duplicates('ko') # 한국어 중복 제거\n",
    "print(f'한국어 중복제거 len {len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f8f2ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 중복제거 len 74849\n"
     ]
    }
   ],
   "source": [
    "data = data.drop_duplicates('en')\n",
    "print(f'영어 중복제거 len {len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8556796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
    "    mecab = Mecab()\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence) # 중간에 중복 공백 하나로\n",
    "    sentence = re.sub(r\"[^가-힣0-9a-zA-Z?.!,]+\", \" \", sentence) # 한글, 영어만 남기고 ? . ! , 남기고\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d794fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ko'] = data['ko'].apply(preprocess_sentence)\n",
    "data['en'] = data['en'].apply(lambda x: preprocess_sentence(x, s_token=True, e_token=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "814ec82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6ee1e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ko'] = data['ko'].apply(lambda x: ' '.join(mecab.morphs(x))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97984b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['ko'].apply(lambda x: len(x.split()) <= 40)) & (data['en'].apply(lambda x: len(x.split()) <= 40))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f84de774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>개인 용 컴퓨터 사용 의 상당 부분 은 이것 보다 뛰어날 수 있 느냐 ?</td>\n",
       "      <td>&lt;start&gt; Much of personal computing is about ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>모든 광 마우스 와 마찬가지 로 이 광 마우스 도 책상 위 에 놓 는 마우스 패드 ...</td>\n",
       "      <td>&lt;start&gt; so a mention a few weeks ago about a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그러나 이것 은 또한 책상 도 필요 로 하 지 않 는다 .</td>\n",
       "      <td>&lt;start&gt; Like all optical mice, But it also doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>결정 적 인 순간 에 그 들 의 능력 을 증가 시켜 줄 그 무엇 이 매우 중요 합니다 .</td>\n",
       "      <td>&lt;start&gt; Something that will boost their capabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>연구가 들 이 이미 커피 대체 품 으로서 음식 대용 과자 나 껌 에 카페인 을 첨가...</td>\n",
       "      <td>&lt;start&gt; Researchers are already exploring ways...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94118</th>\n",
       "      <td>우리 는 3 월 8 일 김승연 회장 과 그 의 아들 이 보복 폭행 에 가담 한 혐의...</td>\n",
       "      <td>&lt;start&gt; We are hoping to seize material eviden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94119</th>\n",
       "      <td>월요일 술집 종업원 6 명 은 김 회장 과 아들 에게 폭행 을 당했 음 을 진술 했...</td>\n",
       "      <td>&lt;start&gt; On Monday, police secured statements f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94120</th>\n",
       "      <td>그러나 불 충분 한 증거 확보 로 수사 에 어려움 이 있 다 .</td>\n",
       "      <td>&lt;start&gt; But the lack of material evidence is m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94121</th>\n",
       "      <td>김 회장 과 그 의 아들 은 보복 폭행 혐의 를 강력히 부인 하 고 있 다 .</td>\n",
       "      <td>&lt;start&gt; Kim and his son both deny the allegati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94122</th>\n",
       "      <td>경찰 은 김 회장 의 집무실 에서 추가 증거 를 찾 은 이후 가능 한 한 오늘 김 ...</td>\n",
       "      <td>&lt;start&gt; Police are planning to seek arrest war...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59309 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      ko  \\\n",
       "0               개인 용 컴퓨터 사용 의 상당 부분 은 이것 보다 뛰어날 수 있 느냐 ?   \n",
       "1      모든 광 마우스 와 마찬가지 로 이 광 마우스 도 책상 위 에 놓 는 마우스 패드 ...   \n",
       "2                       그러나 이것 은 또한 책상 도 필요 로 하 지 않 는다 .   \n",
       "8      결정 적 인 순간 에 그 들 의 능력 을 증가 시켜 줄 그 무엇 이 매우 중요 합니다 .   \n",
       "9      연구가 들 이 이미 커피 대체 품 으로서 음식 대용 과자 나 껌 에 카페인 을 첨가...   \n",
       "...                                                  ...   \n",
       "94118  우리 는 3 월 8 일 김승연 회장 과 그 의 아들 이 보복 폭행 에 가담 한 혐의...   \n",
       "94119  월요일 술집 종업원 6 명 은 김 회장 과 아들 에게 폭행 을 당했 음 을 진술 했...   \n",
       "94120                그러나 불 충분 한 증거 확보 로 수사 에 어려움 이 있 다 .   \n",
       "94121        김 회장 과 그 의 아들 은 보복 폭행 혐의 를 강력히 부인 하 고 있 다 .   \n",
       "94122  경찰 은 김 회장 의 집무실 에서 추가 증거 를 찾 은 이후 가능 한 한 오늘 김 ...   \n",
       "\n",
       "                                                      en  \n",
       "0      <start> Much of personal computing is about ca...  \n",
       "1      <start> so a mention a few weeks ago about a r...  \n",
       "2      <start> Like all optical mice, But it also doe...  \n",
       "8      <start> Something that will boost their capabi...  \n",
       "9      <start> Researchers are already exploring ways...  \n",
       "...                                                  ...  \n",
       "94118  <start> We are hoping to seize material eviden...  \n",
       "94119  <start> On Monday, police secured statements f...  \n",
       "94120  <start> But the lack of material evidence is m...  \n",
       "94121  <start> Kim and his son both deny the allegati...  \n",
       "94122  <start> Police are planning to seek arrest war...  \n",
       "\n",
       "[59309 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "202cff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus, vocab_size):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa0a36f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_vocab_size = 10000\n",
    "en_vocab_size = 10000\n",
    "\n",
    "ko_corpus = data['ko'].tolist()\n",
    "en_corpus = data['en'].tolist()\n",
    "\n",
    "# 각각 tokenize 적용\n",
    "enc_tensor, enc_tokenizer = tokenize(ko_corpus, ko_vocab_size)\n",
    "dec_tensor, dec_tokenizer = tokenize(en_corpus, en_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77c4f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc)\n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)\n",
    "\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
    "        \n",
    "        attn = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vec = attn * h_enc\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
    "\n",
    "        return context_vec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c49a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units,\n",
    "                                       return_sequences=True)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f30b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "\n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "        \n",
    "        out, h_dec = self.gru(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2676835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE     = 128\n",
    "SRC_VOCAB_SIZE = ko_vocab_size + 1\n",
    "TGT_VOCAB_SIZE = en_vocab_size + 1\n",
    "\n",
    "units         = 1024\n",
    "embedding_dim = 128\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07daaa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence_len = 30\n",
    "\n",
    "# sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
    "# sample_output = encoder(sample_enc)\n",
    "\n",
    "# print ('Encoder Output:', sample_output.shape)\n",
    "\n",
    "# sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
    "\n",
    "# sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "#                                      sample_state, sample_output)\n",
    "\n",
    "# print ('Decoder Output:', sample_logits.shape)\n",
    "# print ('Decoder Hidden State:', h_dec.shape)\n",
    "# print ('Attention:', attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02bbc610",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "155754a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1]\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c6dfa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 464/464 [06:42<00:00,  1.15it/s, Loss 3.4307]\n",
      "Epoch  2: 100%|██████████| 464/464 [05:11<00:00,  1.49it/s, Loss 3.3982]\n",
      "Epoch  3: 100%|██████████| 464/464 [05:21<00:00,  1.44it/s, Loss 3.1262]\n",
      "Epoch  4: 100%|██████████| 464/464 [05:19<00:00,  1.45it/s, Loss 3.0793]\n",
      "Epoch  5: 100%|██████████| 464/464 [05:19<00:00,  1.45it/s, Loss 2.9934]\n",
      "Epoch  6: 100%|██████████| 464/464 [05:20<00:00,  1.45it/s, Loss 2.9534]\n",
      "Epoch  7: 100%|██████████| 464/464 [05:19<00:00,  1.45it/s, Loss 2.9268]\n",
      "Epoch  8: 100%|██████████| 464/464 [05:20<00:00,  1.45it/s, Loss 2.9074]\n",
      "Epoch  9: 100%|██████████| 464/464 [05:20<00:00,  1.45it/s, Loss 2.8901]\n",
      "Epoch 10: 100%|██████████| 464/464 [05:20<00:00,  1.45it/s, Loss 2.8752]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm    # tqdm\n",
    "import random\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_tensor.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)    # tqdm\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_tensor[idx:idx+BATCH_SIZE],\n",
    "                                dec_tensor[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bb7f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder):\n",
    "    attention = np.zeros((dec_tensor.shape[-1], enc_tensor.shape[-1]))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = enc_tokenizer.texts_to_sequences([sentence])\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                           maxlen=enc_tensor.shape[-1],\n",
    "                                                           padding='post')\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    enc_out = encoder(inputs)\n",
    "\n",
    "    dec_hidden = enc_out[:, -1]\n",
    "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(dec_tensor.shape[-1]):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
    "\n",
    "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
    "    plot_attention(attention, sentence.split(), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "481bbb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51/1234604866.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_51/1234604866.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 50724 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 48148 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 47560 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 45716 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 45824 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 53685 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 47161 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51060 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 45796 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 50724 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 48148 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 47560 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 45716 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 45824 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 53685 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 47161 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51060 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 45796 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"오바마는 대통령이다.\", encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9ca5ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51/1234604866.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_51/1234604866.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49884 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 48124 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 46308 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51008 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49549 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49328 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49884 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 48124 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 46308 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51008 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49549 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49328 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"시민들은 도시 속에 산다.\", encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6634b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the united states to be the united states to be the united states to be the united states to be the united states to be the united states to be the united states to be the united states to be \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51/1234604866.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_51/1234604866.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 52964 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 54588 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 54596 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 50630 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 52964 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 54588 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 54596 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 50630 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGsAAAJRCAYAAABCwUnuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUDElEQVR4nO2dfbBdVXnGnychEAhQEoilQSRFRg0BAmnEaG1kpkVLaR0n0GEUOpV2SkfM2JahTMeOSIXSpkZpp4CaigY7jNPBDoOBtlBb8aPyFbUGgUiFXD4FEgJp0oR8vv1j7Zvse8/a55x9k3vO++79/GYykLv3Omff82Ttvde711k/mhlEDKYM+wBE/yisQCisQCisQCisQCisQCisQCisQBwy7AMYJCQ/BuCYGk1eMLMvTtLh1IZtqmCQXAvgSgDss8m1Znb2JB5SLVrVswDsMbN7+92Z5HWTeTB1ads1q+5pxNVpp21hhUZhDRGSt5L8j373b9s1axrJJX3uS/R/IzJRiBodpm13g1cBmFmjyXNmdtNkHU9d2hbWHNQ7m+wws5cG3a5qY9vCWgfgB0inn16/OAG82czOHteuHw6oXdXGtl2ztpvZh/rdmeTDQ2qXpW13gxMdZw26XZa2hRUahRUIhdWdiY6zJqVd224wdpL8Xo39NwypXZa2hbUewPE19n96SO2ytC2stwJYjP5OUwTw7SG1y9K2sGhmO/vemRz9kAfdLkvbbjA0zhKDQWEFom3XrMNJXt3nvuXrx6Db5XdoWdV9CYDDazTZbGYPDLpd1cZWhRUdXbMCobACobAKSF42iDYH0k5h7WciH+CEPvSJtlNYgWjV3eBxs6ba3BOnZbdteGUPZh87NbvtibVHZH++CzswDYfVPo5u7bbg1Y1mNju3rVWD4rknTsND95xYu9375px58A+mgm/Y1yofk7g5DZI8h6SRPG7Yx+KVoYVF8j6SNw7r/SPipmeJ3gwlLJKrALwHwEeLU58BmFtsXkDyQZLbSK4huXBc23eR/Fax/XmSnyN59GB/g+EwrJ71RwDuB/BlAL9Q/Hm22PZXAP4MwEIArwC4bfQJKsnTAdwL4OsAFgBYCuBMAF+qeiOSlxWhr9nwyp5J+WUGxVDuBs1sM8mdALaZ2YsAQPJtxeZPmNk3i599CsB3AZwA4DkAfwrgn8zsM6OvRfIjAH5I8g1m9nLmvVYCWAkAixZMDz1O8Xjrvrb0/y8U/30DUli/BOAUkheV9hl9DvRmAB1hNQmPYe0q/f9oT5hS+u8XAdyQaff8ZB6UB4YZ1k4A+ZJBNT8AMN/MfjoJx+OeYd66jwA4m+TcYiDcz7EsL9p8nuRZJE8h+ZskvzCpR+qEYYa1Aql3PYY0bfhNvRqY2VoAS5Bu878F4EdId4+V3xZsEkM7DZrZEwDeOe7Hq8btM4JxE0nMbA2AX5/Ie27cMw23bK4zmznBRafVbmNrfly7TS9UwQjEQMKazDogybuKikjjGdRpcClKt+QkRwDcaGYrBvT+jWAgYZnZpkG8T9PpeRrMncJIriJ5V2n7zSSvJ7mR5MskV5CcknsNkvcBOAnAp0tF3NH9uhZpSR5RvPdWki+R/PgBfwKBOFjXrIsB7AbwLgDLAPwxgIsq9l2KVDr6FPYXcfst0q4AcC6ACwD8KoCzkG7lW8HBOg0+Zmajc7qfIPkHSB/mV8fvaGabSO4BsGW0iFvQtUgLYBuA3wfwe2Z2T7H9UqTgKymmfV0GALPm1J8v4YmDFdbacX9/Aan4WodeRdptAA5FerQCADCzrSQf6fai5ar73NOOanzVfS86v+EwforQrnF/N9Q/xfYq0r6l5us1jn7C2oDiulJiAVJtb6Lkirhdi7Qkn0T6R7EYwFPFz2YAOA3AkwdwLGHo51//fwI4j+T7Sb6V5GcB1J/PNZYRAL9C8oTSbKauRVoz2wrgFgDLSZ5Lcj7SzUfdyn1Y+ulZXwJwBvbfld0E4A4ABzJl7GoAX0DqEYchTTZdW3yf6TqkIu1UpB50R6ndlQBmFD/bBuDvi7+3glbNyJ196rH2ga+cX7vdumtPr91m+uqHarcBgG/Y175vZoty21TIDYTCCoTCCsRBCYvkh0lunUA7zW+vgXpWIGqFRXIJyQeKqvdmkg+RXIY0s3bGaBWd5DXF/peQfJjklqIafzvJE4ptcwF8s3jpDUW7VcU2kryK5JMkt5N8hOQl447lapJPk9xB8kWSXzmgTyIAfdcGSR4C4E6kgenFSCWnhQAeRaqyX49UwwOA0VPioQA+CWAd0rhsOVJxdwnSdOkLAPwzgPkANgHYXrS7DsCFAD4K4CdIczX+geSrZnY3yQuQxlwfBPAIUh1yca3fPCB1CrlHI7mnVpvZaHlnHQCQPAuAjauiw8zKjzeeKqroj5N8o5k9R3L0oeTLZraxeK0ZAK4A8F4z+06xfT3Js5HCuxvpedjPANxrZrsAPANgTe6gy1X3I4+PPX7u+zRYPO1dBeAekneTvIJk1+ljJBeSvLM4XW3B/g+0W7tTAUwH8G/F6XZrcfPyEezvubcX+6wneQvJ3yaZff5hZivNbJGZLZo+M/YjklrXLDO7FMA7kBYxfD+An5B8X27foofcg1QW+h0Ab8f+KWSH9nFMv4X08HH0z3wA7y2O41mkhRf/EMD/AvgMgO8X79lYat8NmtmPzGy5mZ0D4D4Av4t8Ff1tSNepj5vZt81sHTqfcY0unFhu+xiAHQBOMrOfjvuz7/u2Zva6md1tZn+C9A9hPoBfrvv7RKLODcYvIv1L/jrS86WTkQq8n0Oqok8neS6AHyL1pmeQPvRlJG8CMA/AteNe9mmkZ1/nk1yNZBjYQnIFgBUkR5ciPRLpBmKvma0k+eHi2B9Eupm5COnxyf/U/QAiUadnbUN6AHg7gCcA3ArgNgDLzex7AD6PdKe3AcBVZrYBqdd9AKm3fBLpxmEfZvZ88fO/RJoCPTox5xMArkG643sUwL8j3TmuL7a/hvSI/zsAflxsW2pmo9sbSauq7iefPsOuv2Ne7XZfvvC82m32rl1Xuw2gqntjUFiBcB1WboJpm3EdlhiL27CYWSuD6VuSS5jWyXi9mEJ9A8lug+zG4DYs5NfK2AXgX5HGcmch3b5/EOnbj43HbVhmthmpwrHNzF4sisSXI832vdzMHjezu5AWOFlGMrvOHEuLlmzZtHtgxz8ZuA2rgnkAHjCzvaWffRep1nhKrkG5kHvULI8rSfRPtLC60fjRvfewxheIHwewmKXvfgF4d7Ff46dQew9rBGPXyrgZwBwAN5OcR/J8AH+N9JXXbUM8zoHgPazxa2VMA3Ae0p3gfyNN6f4qgFZ8A9L1FbdirYwRpAegtdltU7Fhd/2lCfdOzy+CPGi89yxRQmEFwl1YKt5W4y4sUY3CCoTXsA4h+XckXy3+fHp0IEzyUJLLST7HtLjJw1XT4ZqG17AuRjq2dyLNqLoMaYo2kKrw7wHwIaQvf98KYDXJBYM/zMHidZz1MwAfszSbZx3JtwC4guSdSI9E5prZM8W+N5L8NaRQLx//QuXp0zODL1ritWc9YGOnXd2PtFz4u5HW5Hhs3NTq87F/avUYylX3I2fGfkbptWd1w5Bm4I5fKGV7Zt9G4TWsd5BkqXctRnroeD9Szzp+dKH+NuH1NDgHwN8yLZJyIdIiXDcUtcLbAKwieSHJk0kuInklyaVDPeIB4LVn3Yb0HOtBpNPeLdi/ptOlAP4cwN8AeCPSl/Aewv5vUTYWd2EV304ZZVlm+y6kefDX1H3tGVN24O2HP1X7mP7lpTNrt5mM2R5eT4Mig8IKhJuwtCZGb+R8DISbniV6I+djIFrlfHxtk5yPtRmW83HeGYeFnrXrblAMOR8r8RiWnI8VyPkYCDkfAyHnYyBa5Xz8v72H4eHtJ9dut/vnj6n/Zk8/23ufmqiCEQg5HwMh52Mg5HwMhJyPgZDzMRCtcj5Gnz7dKufjm047uvFVdzkfnSDnYyDkfAyEnI+BaNXq07NPPdYu+MffqN3u0b84o3ab6XfJ+dhqFFYgFFYg5HwMhHpWIOR8DIScj4GQ8zEQcj4GQs7HQMj5GAg5HwMh52MgWlV1l/NRDAyFFQjXYeUmmLYZ12GJsbgNi3I+duA2LMj52IHbsOR87MRtWBXI+dgQGj+69x6WnI8lvIc1Ajkf9+E9LDkfS7i+4h5s5+Mem4JNu4+s3U7OR1EbhRUId2GpeFuNu7BENQorEF7DkvMxg9ew5HzM4HWcNSnOx1nBFy3x2rMmyfnoY3A7Ubz2rG7I+egMOR8zeD0NyvmYwWvPkvMxg7uwJtP5eMSUnVh4+EjtY1r90mu128j52HIUViDchKU1MXoj52Mg3PQs0Rs5HwMh52Mg5HwMhLtBMeR8rMRjWHI+ViDnYyDkfAyEnI+BkPOxD+R8FLWR8zEQcj4GQs7HQMj5GAg5HwMh52Mg5HwMhJyPgZDzMRByPgZCzsdAtGr1aTkfxcBQWIFQWIGQ8zEQ6lmBkPMxEHI+BkLOx0DI+RgIOR8DIedjIOR8DIScj4FoVdVdzkcxMBRWIFyHlZtg2mZchyXG4jYsyvnYgduwIOdjB27DkvOxE7dhVSDnY0No/Ojee1hyPpbwHtYI5Hzch/ew5Hws4fqKK+fjWLz3LFFCYQXCXVgq3lbjLixRjcIKhNew5HzM4DUsOR8zeB1nyfmYwWvPkvMxg9ee1Q05H50h52MGr6dBOR8zeO1Zcj5mcBeWnI/VeD0NigxuwtIyC72RRjAQbnqW6I00goFovEawSTReI1gu5B5/QuxFPz1es6o0gkBaofqScUXc/yq29SzkHjMrdljuBsWQRrASaQQDIY1gIKQRDESrNILR8XiDMWnI+SgGhpyPgZDzMRByPgZCzsdAyPkYCDkfAyHnYyDkfAyEnI+BkPMxEHI+BqJVq0/L+SgGhsIKhMIKhJyPgVDPCoScj4GQ8zEQcj4GQs7HQMj5GAg5HwMh52Mg5HwMRKuq7nI+ioGhsALhOqzcBNM24zosMRa3YVHOxw7chgU5HztwG5acj524DasCOR8bQuNH997DkvOxhPewRiDn4z68hyXnYwnXV1w5H8fivWeJEgorEO7CUvG2GndhiWoUViC8hiXnYwavYcn5mMHrOEvOxwxee5acjxm89qxuyPnoDDkfM3g9Dcr5mMFrz5LzMYO7sOR8rMbraVBkcBOWllnojZyPgXDTs0Rv5HwMhJyPgZDzMRAer1lyPlbgblAMOR8rkfMxEHI+BkLOx0DI+RgIjzcYk4acj2JgyPkYCDkfAyHnYyDkfAyEnI+BkPMxEHI+BkLOx0DI+RgIOR8DIedjIFq1+rScj2JgKKxAKKxAyPkYCPWsQMj5GIjGOx/ZII1g452P5ULu7FOPDT2obLzzsUnI+RgIOR8DIedjIOR8DESrqu5yPoqBobAC4Tqs3ATTNuM6LDEWt2FRzscO3IYFOR87cBuWnI+duA2rAjkfG0LjR/few5LzsYT3sEYg5+M+vIcl52MJ11dcOR/H4r1niRIKKxDuwlLxthp3YYlqFFYgvIYl52MGr2HJ+ZjB6zhLzscMXnuWnI8ZvPasbsj56Aw5HzN4PQ3K+ZjBa8+S8zGDu7DkfKzG62lQZHATlpZZ6I2cj4Fw07NEb+R8DIScj4GQ8zEQHq9Zcj5W4G5QDDkfK5HzMRByPgZCzsdAyPkYCI83GJOGnI9iYMj5GAg5HwMh52Mg5HwMhJyPgZDzMRByPgZCzsdAyPkYCDkfAyHnYyBatfq0nI9iYCisQCisQMj5GAj1rEDI+RgIOR8DIedjIOR8DIScj4GQ8zEQcj4GQs7HQLSq6i7noxgYCisQrsPKTTBtM67DEmNxGxblfOzAbViQ87EDt2HJ+diJ27AqkPOxITR+dO89LDkfS3gPawRyPu7De1hyPpZwfcWV83Es3nuWKKGwAuEuLBVvq3EXlqhGYQXCa1hyPmbwGpacjxm8jrPkfMzgtWfJ+ZjBa8/qhpyPzpDzMYPX06Ccjxm89iw5HzO4C0vOx2q8ngZFBjdhaZmF3sj5GAg3PUv0Rs7HQMj5GAg5HwPh8Zol52MF7gbFkPOxEjkfAyHnYyDkfAyEnI+B8HiDMWnI+SgGhpyPgZDzMRByPgZCzsdAyPkYCDkfAyHnYyDkfAyEnI+BkPMxEHI+BqJVq0/L+SgGhsIKhMIKhJyPgVDPCoScj4GQ8zEQcj4GQs7HQMj5GAg5HwMh52Mg5HwMRKuq7nI+ioGhsALhOqzcBNM24zosMRa3YVHOxw7chgU5HztwG5acj524DasCOR8bQuNH997DkvOxhPewRiDn4z68hyXnYwnXV1w5H8fivWeJEgorEO7CUvG2GndhiWoUViC8hiXnYwavYcn5mMHrOEvOxwxee5acjxm89qxuyPnoDDkfM3g9Dcr5mMFrz5LzMYO7sOR8rMbraVBkcBOWllnojZyPgXDTs0Rv5HwMhJyPgZDzMRAer1lyPlbgblAMOR8rkfMxEHI+BkLOx0DI+RgIjzcYk4acj2JgyPkYCDkfAyHnYyDkfAyEnI+BkPMxEHI+BkLOx0DI+RgIOR8DIedjIFq1+rScj2JgKKxASCMYCPWsQEgjGIjGawSbROM1gmyQ87HxGsHy9OnpM2NX3aURDIQ0goGQRjAQ0ggGQoXcPvBSyG3V9Omjpr6Oc37u8drt1j8zt3abvb13qY3KTYFQWIFwHVZugmmbcR2WGIvbsCjnYwduw4Kcjx24DUvOx07chlWBnI8NofGlGO9hyflYwntYI5DzcR/ew5LzsYTrK66cj2Px3rNECYUVCHdhqXhbjbuwRDUKKxBew5LzMYPXsOR8zOB1nCXnYwavPUvOxwxee1Y35Hx0hpyPGbyeBuV8zOC1Z8n5mKFVc91JbkD65kqO4wBsrPmSE2nTq91JZjY7t6FVYXWD5JqqLwQczDYH0s7rNUtkUFiBUFj7WTmgNhNup2tWINSzAqGwAqGwAqGwAqGwAvH/7fuK8ydIoTIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"커피는 필요 없다.\", encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ab4e22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the than the than the than the than the than the than the than the than the than the than the than the than the than the than the than the than the than the than the than the than \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51/1234604866.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_51/1234604866.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51068 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44273 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 47749 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51032 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49324 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 47581 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51088 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44032 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 48156 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 54664 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51068 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44273 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 47749 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51032 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49324 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 47581 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51088 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44032 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 48156 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 54664 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"일곱 명의 사망자가 발생했다.\", encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393a5e8",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e24aa6a",
   "metadata": {},
   "source": [
    "- 모델이 학습을 제대로 못해서 결과가 이상하게 나왔다. 학습 loss가 줄어들지 않는 모습이다\n",
    "- 고민을 했지만 원인을 파악하지 못했다. 데이터가 문제인가 모델 구조가 문제인가.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c0b315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68881d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c04b8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6ed06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8bb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
